# nvdspreprocess configuration for tiled inference
# This plugin processes frames BEFORE nvinfer and implements custom tiling

[property]
enable=1
target-unique-ids=1
network-input-order=0
process-on-frame=1
gpu-id=0
unique-id=5
# Processing dimensions must match network input size (ROI scaling)
processing-width=640
processing-height=640
scaling-pool-compute-hw=0
scaling-pool-memory-type=0
scaling-filter=1
scaling-buf-pool-size=4
tensor-buf-pool-size=4
# Tiled batch: 8 x 3 x 640 x 640
network-input-shape=8;3;640;640
network-color-format=0
# FP16 to match model_day_b8_gpu0_fp16.engine input datatype
tensor-data-type=1
tensor-name=input
custom-lib-path=/opt/nvidia/deepstream/deepstream/lib/gst-plugins/libcustom2d_preprocess.so
custom-tensor-preparation-function=CustomTensorPreparation

[user-configs]
# Required by default DeepStream preprocess lib
pixel-normalization-factor=0.003921568
offsets=0;0;0

[group-0]
src-ids=0
process-on-roi=1
# Attach ROI crop meta so nvinfer can map detections back to full frame
dest-crop-rect-user-meta=1
# 8 ROI tiles (4x2 grid with overlap). nvdspreprocess will scale each ROI to 640x640.
roi-params-src-0=0;0;640;640;544;0;640;640;1088;0;640;640;1632;0;288;640;0;544;640;536;544;544;640;536;1088;544;640;536;1632;544;288;536
